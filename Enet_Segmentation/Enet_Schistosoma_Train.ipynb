{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2299bfe0-3291-4e87-be5a-e1de662b3edf",
   "metadata": {},
   "source": [
    "# ENet Train\n",
    "\n",
    "This code ist based on the Enet impementation of following GitHub repository: https://github.com/iArunava/ENet-Real-Time-Semantic-Segmentation <br/>\n",
    "Link to the Enet paper: https://arxiv.org/pdf/1606.02147.pdf <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58a4444-de62-41d6-814f-03a5d850ae88",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81aecf7-8dd7-4fda-bf40-75d4eff22785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "\n",
    "from enetModules.ENet import ENet\n",
    "from enetModules.Utils import Utils\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e10d93-121a-4025-9593-98e34db36a4a",
   "metadata": {},
   "source": [
    "# Default Settings\n",
    "**Change paths here if necessary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a872e25d-c6b2-411f-af1d-07ae776d6213",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True\n",
    "batch_size = 10\n",
    "epochs = 120\n",
    "learn_rate = 5e-4\n",
    "save_every = 5\n",
    "n_classes = 2\n",
    "weight_decay = 2e-4\n",
    "description = \"Diese System wurde mit den unbehandelten River Blindness Datensatz trainiert. Datenaugmentierung wurde angewendet und der Datensatz wurde um weiter Bilder erweitert(+Red). Validation set wurde separiert und augmentiert.\"\n",
    "\n",
    "path_save_model = \"./model/\"\n",
    "#path_images = \"../../content/SchistosomaMansoni/img/\"\n",
    "#path_labels = \"../../content/SchistosomaMansoni/labels/\"\n",
    "#path_images_val = \"../../content/SchistosomaMansoni/val_img/\"\n",
    "#path_labels_val = \"../../content/SchistosomaMansoni/val_labels/\"\n",
    "path_images = \"../../content/RiverBlindness/img/\"\n",
    "path_labels = \"../../content/RiverBlindness/labels/\"\n",
    "path_images_val = \"../../content/RiverBlindness/val_img/\"\n",
    "path_labels_val = \"../../content/RiverBlindness/val_labels/\"\n",
    "\n",
    "with open(path_save_model + \"logs/settings.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    settings = { \n",
    "        \"cuda\": cuda,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"epochs\": epochs,\n",
    "        \"learn_rate\": learn_rate,\n",
    "        \"n_classes\": n_classes,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"description\": description\n",
    "    }\n",
    "    \n",
    "    json.dump(settings, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c55195b-6234-44d3-8f7c-8a994354ec26",
   "metadata": {},
   "source": [
    "# Trainings Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeaebf1-e364-4e1d-a601-95bcd9f7810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_filenames = np.array(os.listdir(path_images))\n",
    "input_train = []\n",
    "\n",
    "label_filenames = np.array(os.listdir(path_labels))\n",
    "label_train = []\n",
    "\n",
    "assert(len(img_filenames) == len(label_filenames))\n",
    "\n",
    "print(\"[INFO]Loading trainings dataset.\")\n",
    "# Reading train images and labels                      \n",
    "for file in tqdm(img_filenames):    \n",
    "    img = Image.open(path_images + file)\n",
    "    label = Image.open(path_labels + file)\n",
    "    augmented_imgs, augmented_labels = Utils.imageAugmentation(img, label)\n",
    "        \n",
    "    for aug_img in augmented_imgs:\n",
    "        img = cv2.resize(np.array(aug_img), (512, 512), cv2.INTER_NEAREST)\n",
    "        input_train.append(img[:,:,0:3]) # cutting out potential alpha channel\n",
    "      \n",
    "    for aug_label in augmented_labels:\n",
    "        label = cv2.resize(np.array(aug_label), (512, 512), cv2.INTER_NEAREST)\n",
    "        label_train.append(label)\n",
    "\n",
    "input_train = np.stack(input_train, axis=2)\n",
    "input_train = torch.tensor(input_train).transpose(0, 2).transpose(1, 3)\n",
    "\n",
    "label_train = np.array(label_train) \n",
    "label_train = torch.tensor(label_train)\n",
    "\n",
    "val_img_filenames = np.array(os.listdir(path_images_val))\n",
    "input_val = []\n",
    "\n",
    "val_label_filenames = np.array(os.listdir(path_labels_val))\n",
    "label_val = []\n",
    "\n",
    "assert(len(val_img_filenames) == len(val_label_filenames))\n",
    "\n",
    "print(\"[INFO]Loading validation dataset\")\n",
    "# Reading validation images and labels. Validation set should not be augmented\n",
    "for file in tqdm(val_img_filenames):\n",
    "    val_img = Image.open(path_images_val + file)\n",
    "    val_img = cv2.resize(np.array(val_img), (512, 512), cv2.INTER_NEAREST)\n",
    "    input_val.append(val_img[:,:,0:3])\n",
    "    \n",
    "    val_label = Image.open(path_labels_val + file)\n",
    "    val_label = cv2.resize(np.array(val_label), (512, 512), cv2.INTER_NEAREST)\n",
    "    label_val.append(val_label)\n",
    "\n",
    "input_val = np.stack(input_val, axis=2)\n",
    "input_val = torch.tensor(input_val).transpose(0,2).transpose(1,3)\n",
    "\n",
    "label_val = np.array(label_val)\n",
    "label_val = torch.tensor(label_val)\n",
    "\n",
    "batch_count_train = (len(input_train) // batch_size)\n",
    "batch_count_val = (len(input_val) // batch_size)\n",
    "\n",
    "if((len(input_train) / batch_size) % 1 != 0):\n",
    "    batch_count_train += 1\n",
    "\n",
    "if((len(input_val) / batch_size) % 1 != 0):\n",
    "    batch_count_val += 1\n",
    "\n",
    "print(\"[INFO]Starting to define the class weights...\")\n",
    "class_weights = Utils.get_class_weights(label_train, n_classes)\n",
    "print(\"[INFO]Fetched all class weights successfully!\")\n",
    "\n",
    "enet = ENet(n_classes)\n",
    "print(\"[INFO]Model Instantiated!\")\n",
    "\n",
    "# Checking for cuda\n",
    "if(torch.cuda.is_available() & cuda):\n",
    "    print(\"[INFO]CUDA is available!\")\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    print(\"[INFO]CUDA isn't available!\")\n",
    "    device = torch.device(\"cpu\")\n",
    "                \n",
    "enet = enet.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor(class_weights).to(device))\n",
    "optimizer = torch.optim.Adam(enet.parameters(),\n",
    "                                lr=learn_rate,\n",
    "                                weight_decay=weight_decay)\n",
    "print(\"[INFO]Defined the loss function and the optimizer\")                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fb0f5b-6e80-47e0-a02b-2d1e6d47f545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"[INFO]Starting Training...\")\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for e in range(1, epochs + 1):\n",
    "    train_loss = 0\n",
    "    print (\"-\"*15,\"Epoch %d\" % e , \"-\"*15) \n",
    "\n",
    "    enet.train()\n",
    "\n",
    "    for _ in tqdm(range(batch_count_train)):                \n",
    "        X_train, y_train = input_train[batch_size * _: batch_size * (_ + 1)], label_train[batch_size * _: batch_size * (_ + 1)]        \n",
    "        X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = enet(X_train.float())        \n",
    "        loss = criterion(out, y_train.long())           \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    print()\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    print ('Epoch {}/{}...'.format(e, epochs),\n",
    "            'Loss {:6f}'.format(train_loss))\n",
    "\n",
    "    with torch.no_grad():                \n",
    "        print()\n",
    "        print(\"Validation:\")\n",
    "\n",
    "        # Validates the model\n",
    "        enet.eval()              \n",
    "        val_loss = 0\n",
    "\n",
    "        for _ in tqdm(range(batch_count_val)):           \n",
    "            X_val, y_val = input_val[batch_size * _: batch_size * (_ + 1)], label_val[batch_size * _: batch_size * (_ + 1)]           \n",
    "            X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "\n",
    "            out = enet(X_val.float())\n",
    "            loss = criterion(out, y_val.long())\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "        print('Loss {:6f}'.format(val_loss))\n",
    "\n",
    "        val_losses.append(val_loss)            \n",
    "\n",
    "    if e % save_every == 0:\n",
    "        checkpoint = {\n",
    "            'epochs' : e,\n",
    "            'state_dict' : enet.state_dict()\n",
    "        }\n",
    "\n",
    "        torch.save(checkpoint, path_save_model + 'ckpt-enet-{}-{}.pth'.format(e, train_loss))\n",
    "        \n",
    "        with open(path_save_model + \"logs/trainLosses.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(train_losses, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "        with open(path_save_model + \"logs/valLosses.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(val_losses, f, ensure_ascii=False, indent=4) \n",
    "            \n",
    "        print()\n",
    "        print('Model and Losses saved!')\n",
    "\n",
    "    print ('Epoch {}/{}...'.format(e, epochs))\n",
    "print(\"[INFO]Training Process complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "dc8688e06fb41c859b3a1b30abeb667a639c61f56cdaba7eb8e5bd6171de15c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
